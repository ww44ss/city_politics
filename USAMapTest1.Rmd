---
title: "High Performance Reverse-Geo-Coding Model"
author: "Winston Saunders"
date: "September 19, 2016"
output: 
    html_document:
        css: markdown7.css
        toc: true
        toc_depth: 3
        keep_md: true
---

###Summary
This documents the creation of a high performance reverse geo-coding 
  
###Problem Statement


```{r setup, include=TRUE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align='center')
```



```{r libraries}
library(ggmap)
library(dplyr)
library(randomForest)
library(ggmap)
library(googleway)
library(choroplethrMaps)
library(nnet)
library(SDMTools)
library(tidyr)
library(stringr)
library(xtable)
    options(xtable.floating = FALSE)
    options(xtable.timestamp = "")
library(gridExtra)
    
    options(scipen=999)
```



## Use Point-in-Polygon Generated Traininng Set

[Point-in-Polygon](https://en.wikipedia.org/wiki/Point_in_polygon) (P-i-P) is a standard method for computing whether a given point lies inside a given perimeter, such as a political boundary. 
 
To compute P-i-P I used the `{SDMTools}` package, which uses the winding number calculated from a "sum of angles."  
  

```{r}

# define improved pip function

    require(ggmap)
    require(maps)

    if (!exists("counties")) counties <- map_data("county")
    if (!exists("states")) states <- map_data("state")
    if (!exists("state_county")) state_county <- subset(counties, region == 'oregon')

    cities <- us.cities
    
    ## create ciyt_name by removing state designnator
    cities <- cities %>% mutate(city_name = gsub(' [A-Z]*','', name))
    
    cities <- cities[complete.cases(cities),]


    pip.oregon.county <- function(coords.x){
    
    ## input: coords.x = data frame of (lat, lon) pair
    ## returns: data frame with added column pip.county
    ## requires: ggmap and counties data
    coords.x<-as_data_frame(coords.x)
    
    coords.x$pip.county <- rep(0, nrow(coords.x))
    
    for (county.x in unique(state_county$subregion)) {
        
        county.x.boundary <- filter(state_county, subregion == county.x)
        
        A <- pnt.in.poly(coords.x[,1:2], county.x.boundary[,1:2]) %>% as_data_frame
        
        ## this is a little awkward
        ## possibly not good programming practice to index one df from another
        coords.x[A$pip == 1,3] <- county.x
        
        
    }
    
    ## assign "none" to those not in Oregon
    coords.x[coords.x$pip.county == 0,3] <- "outside"
    
    return(coords.x)
}

```
 
```{r}

    ## compute benchmark

    number.to.compute <- 2000

    ## capture a subset of the data
    coords.x <- coords[1:number.to.compute, 1:2] %>% as.data.frame()

    get.county.start.time <- proc.time()
    
        pip.county.result <- pip.oregon.county(coords.x)
    
    
    get.county.time <- (proc.time() - get.county.start.time)[1]

```

```{r}

pip.accuracy <- 1.0  ## assumption could be checked
pip.thruput <- round(number.to.compute/(2000*get.county.time), 12) %>% as.numeric %>% round(2)

```


```{r}

## PiP THROUGHPUT VERSUS NUMBER OF POINTS

n.steps <- 57

data.compile.df <- data_frame("n" = 1.1*1:n.steps, "time" = 1.1*1:n.steps, "time.per.datapoint" = 1.1*1:n.steps)

for (jj in 1:n.steps){
    
    n_coords <- 35*jj
    
    coords.x <- coords[1:n_coords, 1:2] %>% as.data.frame()
    
    get.county.start.time <- proc.time() 

    pip.county.result <- pip.oregon.county(coords.x)
    
    get.county.time <- (proc.time() - get.county.start.time)[1] %>% as.numeric
    
    data.compile.df[jj,1] <- n_coords

    data.compile.df[jj,2] <- round(1000*get.county.time, 2) 
    
    data.compile.df[jj,3] <- round(1000*get.county.time/n_coords, 2) 
}
```


```{r, fig.height=4}

## PLOT PiP THROUGHPUT VERSUS NUMBER OF POINTS

    ggplot(data.compile.df, aes(x = n, y = time)) +
    geom_point(aes(color = 'total.time')) + 
    geom_point(aes(y = time.per.datapoint, color = 'time.per.point')) +
    scale_colour_manual(name='time', labels = c("per point", "total"), values=c('total.time'='#AA3455', 'time.per.point'='#223477')) +
    ggtitle("Point-in-Polygon compute performance") +
    theme(legend.title=element_text(colour="black", size=10, face="bold")) +
    xlab("number of points") +
    ylab("time (msec)") + 
    theme(panel.grid.minor = element_blank()) +
    scale_y_log10(breaks = c(0.2, 1, 2, 10, 20, 100, 200, 1000))

```

In practice, the P-i-P is much faster than the API call. Based on a stand-alone benchmark run, for `r number.to.compute` points, the throughput is `r pip.thruput` points per msec - an improvement of roughly a factor of `r 50* ((pip.thruput/api.thruput/50) %>% round(0))` over the API calls. 

Note, as the number of points get's large, the thruput (points/time) asymptotes to a constant value of roughly `r 1/0.00020` points/msec.

####Comparison of P-i-P to Google Maps API Accuracy 

Initially I had assumed the API method would provide 100% accurate results. However, as I investigated, I was suprised to learn they did not. Indeed errors in the API data contributed about 2% error to the randomForest classifier developed below.  

In order to establish a "grounded truth" for developing a supervised machine learning capability, it's useful to compare the results of the P-i-P and API methods. This is best seen visually by mapping points of agreement adn disagreement between the two methods. 

The code chunk below creates the base maps used in this work. 

```{r eval = FALSE, echo=TRUE}

 ## Create State Map With County Boundaries Overlayed

    library(ggmap)
    map = get_googlemap(center =  c(lon = -120.31619, lat = 44), 
              zoom = 6, size = c(450, 340), scale = 2, source = "google",
              maptype="roadmap") #, key = my.secret.key)

    map.plot = ggmap(map)

    ## get oregon counties

    counties <- map_data("county")
    state_county <- subset(counties, region == 'oregon')

    ## plot map
    map.plot + 
        geom_polygon(data = state_county, aes(x=long, y=lat, group = group), 
                     fill = NA, color = "darkblue") 

```


Points of disagreement between the Google Maps API and the P-i-P method are clearly show the problem is with the API calls. Note that data-points along the coast are excluded as there is a systematic (non-random) difference in how these are classified between the API and P-i-P methods. 

Several points within county interiors don't agree. At this point it's not clear whether the disagreement is an inherent to the Google Maps API reverse geocoding algorithms, or with the way I have interpreted the resulting data (which are returned in a very "untidy" format). This could be investigated with some more effort in data collection.  


```{r}

    ## USE PiP to COMPUTE API ACCURACY

    number.to.compute <- 4000

    set.seed(8675309)
    data.select <- sample(1:nrow(coords), number.to.compute)
    
    ## get rid of points on coast
    
    # coastal <- function(lon, lat) {
    #     coastal <- FALSE
    #     if (lat >=42. && lat < 43.5 && lon <= -124.1) coastal <- TRUE
    #     if (lat >= 43.5 && lat < 45 && lon <= -123.9) coastal <- TRUE
    #     if (lat >=45. && lon <= -123.8) coastal <- TRUE
    #     
    #     return(coastal)
    #     
    # }
    
    coastal <- function(x) {
        
        ## returns TRUE if point is west of coastal Oregon, FALSE otherwise
        ## INPUT: x (at Longitude, latitude pair)
        ## RETURNS: logical (TRUE/FALSE)
        
        coastal <- FALSE
        if (x[2] >=42. && x[2] < 42.75 && x[1] <= -124.2) coastal <- TRUE
        if (x[2] >=42.75 && x[2] < 43.2 && x[1] <= -124.3) coastal <- TRUE
        if (x[2] >=43.2 && x[2] < 43.5 && x[1] <= -124.1) coastal <- TRUE
        if (x[2] >= 43.5 && x[2] < 44 && x[1] <= -124.0) coastal <- TRUE
        if (x[2] >= 44 && x[2] < 45 && x[1] <= -123.9) coastal <- TRUE
        if (x[2] >=45. && x[1] <= -123.8) coastal <- TRUE

        return(coastal)

    }
    
    

    ## capture a subset of data
    coords.x <- coords[data.select, 1:2] %>% as_data_frame()
    
    ## use coastal function to get rid of points
    coastal.vec <- apply(coords.x, 1, coastal)
    coords.x <- coords.x[!coastal.vec, ]
    
    ## compute PiP
    pip.county.result <- pip.oregon.county(coords.x)
    
    api.counties <- coords[data.select, 3] %>% lapply(as.character) %>% lapply(tolower)  %>% as_data_frame
    
    api.counties <- api.counties[!coastal.vec,]
    
    api.counties <- as.factor(api.counties[[1]])
    
    pip.counties <- pip.county.result[,3] %>% as_data_frame
    
    pip.v.api <- cbind(api.counties, pip.counties) 
    
    ## check agreement
    pip.v.api$agree <- pip.v.api[,1] == pip.v.api[,2]
    
    agree.table <- table(pip.v.api$agree)
    
    plot.data <- cbind(coords.x, pip.v.api)
    
    api.accuracy <- (100*agree.table[2]/(agree.table[1]+agree.table[2])) %>% round(1)

```

The accuracy of the API, as graded against the P-i-P method, is `r api.accuracy`%.


```{r fig.align='center'}


## use ggmap

library(ggmap)
map = get_googlemap(center =  c(lon = -120.31619, lat = 44), 
              zoom = 6, size = c(450, 340), scale = 2, source = "google", maptype="roadmap") #, key = "AIzaSyADdNjbHVwefx-jDyDRPkcSIdcZfznFjc8")
map.plot = ggmap(map)

# get oregon counties
counties <- map_data("county")
state_county <- subset(counties, region == 'oregon')

map.plot + 
  geom_polygon(data = state_county, aes(x=long, y=lat, group = group), fill = NA, color = "darkblue") + 
    geom_point(aes(x = lon, y = lat, color = agree), data=plot.data, size = 1.5) +
    scale_color_manual(values=c("#B74611","#77A1D877")) + 
    ggtitle("P-i-P versus API Accuracy") + 
    annotate("text")

```

###Machine Learning Approaches

Since high speed and (not necessarily perfect) accuracy are goals, the question arises, can classification machine learning algorithms be trained well enough to provide adequate accuracy (e.g. close to 98%) and offer a substantial speed advantage?  

####Method  
Supervised machine learning requires a large number of random (latitude, longitude) "grounded truth" data points. Based on the above analysis I generated a set of random (lat, lon) pairs and used the P-i-P method for classification. 

To match the intended use-case, data points are based on random sampling within a (latitude, longitude) "rectangle" that exceeds the size of Oregon. Points are then classified by county if they lie within Oregon, or as "outside" if they do not. 


```{r "generate coords"}

    #generate a random set of coords

    ##Oregon USA
    lat.max <- 46.4
    lat.min <- 41.8
    lon.max <- -116.5
    lon.min <- -124.8
    
    ## create data frame of random geo-coordinates
    df_l <- 21023
    
    set.seed(210257)
    ## unique.int.seed <- as.integer((as.double(Sys.time())*1000+Sys.getpid()) %% 2^31)
    ## set.seed(unique.int.seed)
    
    ## create random coordinates
    ## Use for loop to extract reverse_geocode stuff
    
    coords.t <- data_frame("lon" = runif(df_l, min = lon.min, max = lon.max), "lat" = runif(df_l, min = lat.min, max = lat.max))
    
    

```

For this work, `r nrow(coords)` data points serve as both training and test data sets.

<br>

```{r}
    ## this chunk establishes the grounded truth based on the P-i-P 
    ## strips the API data and replaces it with PiP data. 

    coords.y <- coords[ , 1:2]

    #coords <- pip.oregon.county(coords.y)  # uses values from API calls

    coords <- pip.oregon.county(coords.t)   # uses (lat, lon) values generated above. 

    colnames(coords) <- c("lon", "lat", "county")
    coords$county <- as.factor(coords$county)

```


###Random Forest Classifier Optimization 
####Accuracy and thruput versus `n_train`

Since speed and accuracy are goals, it makes sense to take a broad look at the accuracy and thruput of a `randomForest` model as a function of `n_train`. To standardize evaluation a subset of `n_test` = 2000 test data points are used for each accuracy evaluation, while the value of `n_train` is allowed to vary.  
The number of trees `ntree` = 21 was fixed after some rudimentary exploration. Within fairly wide bounds this produced good results. 

```{r "random forest accuracy"}

    n.accuracy.points <- 21

    ## prebuild results data_frame
    rf.model.char.df <- data_frame("n" = 1:n.accuracy.points, 
                                   "n_train"= 1:n.accuracy.points, 
                                   "model_time" = 1.*1:n.accuracy.points, 
                                   "predict_time" = 1.*1:n.accuracy.points, 
                                   "accuracy" = 1.*1:n.accuracy.points, 
                                   "thruput" = 1.*1:n.accuracy.points, 
                                   "n_test" = 1.*1:n.accuracy.points)

    jj<-21
    
    set.seed(8675309)
    
    for (jj in 1:n.accuracy.points){

                rf.model.char.df[jj,1] <- jj
        
            coords.y <- coords
        
            n_model <- 510+jj*731
            
                rf.model.char.df[jj,2] <- n_model
        
            ## split data sets
            data.select <- sample(1:nrow(coords.y), n_model)
            train.set <- coords.y[data.select,]
            
            
            test.set <- coords.y[-data.select,]
            
                rf.model.char.df[jj, 7] <- nrow(test.set)
            
            
            #set.seed(8675309)
            
            model.start.time <- proc.time()
            
            rf.model <- randomForest(county ~., train.set, ntree=29)
            
                rf.model.char.df[jj,3] <- 1000*(proc.time() - model.start.time)[1]
            
            predict.start.time <- proc.time()
            predicted.test <- predict(rf.model, test.set)
            
                rf.model.char.df[jj,4] <- 1000*(proc.time() - predict.start.time)[1]
            
            county.compare <- cbind("actual" = as.character(test.set$county), "model" = as.character(predicted.test)) %>% as.data.frame()
            county.compare$accurate <- "yes"
            
            ## get rid of factors again
            county.compare$actual <- as.character(county.compare$actual)
            county.compare$model <- as.character(county.compare$model)
            
            county.compare$accurate[(county.compare[,1] != county.compare[,2])] <- "no"
            
            plot.data <- cbind("lat" = test.set$lat, "lon" = test.set$lon, "accurate" = county.compare$accurate) %>% as.data.frame
            
            plot.data$lat <- plot.data$lat %>% as.character %>% as.numeric
            plot.data$lon <- plot.data$lon %>% as.character %>% as.numeric
            
            plot.data$accurate <- as.factor(plot.data$accurate)
        
        
        predict.sum<-table(plot.data$accurate)
        
        ## calculated accuracy in %
        model.accuracy <- (100*predict.sum[2]/(predict.sum[1]+predict.sum[2])) %>% round(3)
        
            rf.model.char.df[jj,5] <- model.accuracy
            
            rf.model.char.df[jj,6] <- n_model/rf.model.char.df[jj,4]
            
    }
    
    #rf.model.char.df
    
```

<style>
  .col2 {
    columns: 2 300px;         /* number of columns and width in pixels */
    -webkit-columns: 2 300px; /* chrome, safari */
    -moz-columns: 2 300px;    /* firefox */
  }
  .col3 {
    columns: 3 200px;
    -webkit-columns: 3 200px;
    -moz-columns: 3 200px;
  }
</style>

<style>
tr:hover {background-color: #BBFFFF}
table { 
    width: 60%;
    display: table;
    border-collapse: collapse;
    border-spacing: 18px;
    border-color: #AAAAFF;
    background-color: #AFEEEE;
    padding: 2px;
    font: 12px arial, sans-serif;
}
th, td{
    text-align: center;
}
</style>

Here is a sample of the data collected
<br>

```{r, results='asis'}

    table.select <- seq(from = 1, to = nrow(rf.model.char.df), by = 4)
    
    print(xtable(rf.model.char.df[table.select,-1]), type = "html", comment=FALSE, 
          include.rownames=FALSE, 
          html.table.attributes='border="3" align="center" ' )
    
```
  
<br>


The accuracy of the `randomForest` improves with the number of points, exceeding 95% accuracy above about 4000 data points. Note that while the model time increases with the number of data points, the time to predict is relatively constant (meaning the predict time per point scales well with the number of points predicted).

```{r, fig.height=3, fig.width=9}

    p1 <- ggplot(rf.model.char.df, aes(x = n_train, y = accuracy)) + geom_point(color = "salmon", size = 2) + ggtitle("accuracy improvement with n_train") + ylim(90, 100) + ylab("accuracy (%)")

    p2 <- ggplot(rf.model.char.df, aes(x = n_train, y = model_time, color = "model", pch="model"), size = 2) + geom_point() +
        geom_point(aes(x = n_test, y = predict_time, color = "predict", pch = "predict"), size = 2) + 
        scale_colour_manual(name='Time', labels = c("model", "predict"), values=c('model'='#AA3477', 'predict'='#77AA34')) +
        scale_shape_manual(name='Time', labels = c("model", "predict"), values=c('model' = 1, 'predict' = 3)) +
        ylab("time (msec)") +
        xlab("n_train and n_test") +
        ggtitle("model & predict total time")+ 
    theme(panel.grid.minor = element_blank()) +
    scale_y_log10(breaks = c(0.02, 0.05, 0.1,0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000))
    
    p3 <- ggplot(rf.model.char.df, aes(x = n_train, y = model_time/n_train, color = "model", pch="model"), size = 2) + geom_point() +
        geom_point(aes(x = n_test, y = predict_time/n_test, color = "predict", pch = "predict"), size = 2) + 
        scale_colour_manual(name='Time', labels = c("model", "predict"), values=c('model'='#AA3477', 'predict'='#77AA34')) +
        scale_shape_manual(name='Time', labels = c("model", "predict"), values=c('model' = 1, 'predict' = 3)) +
        ylab("time (msec)") +
        xlab("n_train and n_test") +
        ggtitle("model & predict time per point")+ 
    theme(panel.grid.minor = element_blank()) +
    scale_y_log10(breaks = c(0.02, 0.05, 0.1,0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000))
    
   

#grid.arrange(p2, p3, ncol=2)

```

```{r fig.align='center', fig.height=4, fig.width=7}
p1
```


Clearly `n_train` has a large influence on the accuracy of the model. Since accuracy near 98% is desired will choose about 15000 data points.  

Computation times (both total and normalize to the number of points) are shown below. Of interest, the modeling time per point for the randomForest is relatively constant. 

```{r, fig.align='center', fig.height=3, fig.width=9 }
grid.arrange(p2, p3, ncol=2)
```




####Performance Benchmark Results

```{r, "rf model"}

    ## RANDOMFOREST BENCHMARK

    coords.y <- coords

    n_model <- 14700

    set.seed(334455)
    data.select <- sample(1:nrow(coords.y), n_model)

    train.set <- coords.y[data.select,]
    
    test.set <- coords.y[-data.select,]
    test.set <- test.set[1:5000,]
    
    set.seed(8675309)
    ntree.x <- 29
    
    start.time <- proc.time()
        rf.model <- randomForest(county ~., train.set, ntree = ntree.x)
    rf.model.time <- (1000*(proc.time() - start.time)[1]) %>% round(1) %>% as.numeric
    rf.model.thruput <- (nrow(train.set) / rf.model.time) %>% round(1)
    
    start.time <- proc.time()
        predicted.test <- predict(rf.model, test.set)
    rf.predict.time <- (1000*((proc.time() - start.time)[1])) %>% as.numeric %>% round(2)
    rf.predict.thruput <- (nrow(test.set) / rf.predict.time) %>% round(1)

```

Performance was measured as shown in the code snippet below. 

```{r eval=FALSE, echo=TRUE}
    set.seed(8675309)
    ## set number of trees
    ntree.x = 29

    ## start model
    start.time <- proc.time()

        rf.model <- randomForest(county ~., train.set, ntree = ntree.x)
        
    rf.model.time <- (1000.*(proc.time() - start.time)[1]) %>% round(1) %>% as.numeric
    rf.model.thruput <- (nrow(train.set) / rf.model.time) %>% round(1)
    
    ## start prediction
    start.time <- proc.time()
    
        predicted.test <- predict(rf.model, test.set)
        
    rf.predict.time <- (1000.*((proc.time() - start.time)[1])) %>% as.numeric %>% round(2)
    rf.predict.thruput <- (nrow(test.set) / rf.predict.time) %>% round(1)

```

In a standardized run it took `r rf.model.time` msec to model the `r nrow(train.set)` data points. Predictions made on the remaining `r nrow(test.set)` data points took `r round(rf.predict.time, 1)` msec, for a throughput of `r rf.predict.thruput %>% round(1)` data points per msec.



```{r}

    county.compare <- cbind("actual" = as.character(test.set$county), "model" = as.character(predicted.test)) %>% as.data.frame()
    county.compare$accurate <- "yes"
    
    ## get rid of factors again
    county.compare$actual <- as.character(county.compare$actual)
    county.compare$model <- as.character(county.compare$model)
    
    county.compare$accurate[(county.compare[,1] != county.compare[,2])] <- "no"
    
    plot.data <- cbind("lat" = test.set$lat, "lon" = test.set$lon, "accurate" = county.compare$accurate) %>% as.data.frame
    
    plot.data$lat <- plot.data$lat %>% as.character %>% as.numeric
    plot.data$lon <- plot.data$lon %>% as.character %>% as.numeric
    
    plot.data$accurate <- as.factor(plot.data$accurate)

```



```{r, results='asis'}
predict.sum<-table(plot.data$accurate)

predict.sum.df <- predict.sum %>% as.data.frame

colnames(predict.sum.df) <- c("accurate", "count")

#print(xtable(predict.sum.df), type = "html", comment=FALSE, include.rownames=FALSE, html.table.attributes='border="3" align="center" ' )

```

Model accuracy is `r (100*predict.sum[2]/(predict.sum[1]+predict.sum[2])) %>% round(1)`%.

```{r}

rf.accuracy <- (100*predict.sum[2]/(predict.sum[1]+predict.sum[2])) %>% round(1)

```

The results of applying a test data set to the model results are mapped below. For the `randomForest` errors appear on the boundaries of counties. No points lie within the interiors. Note that errors occur along both straight and complex boundaries, though error rates appear to increase with boundary complexity. 

```{r fig.align='center'}

    ## State Data and 

library(ggmap)
    map = get_googlemap(center =  c(lon = -120.31619, lat = 44), 
              zoom = 6, size = c(450, 340), scale = 2, source = "google",
              maptype="roadmap") #, key = my.secret.key)

    map.plot = ggmap(map)

    # get oregon counties

    counties <- map_data("county")
    state_county <- subset(counties, region == 'oregon')

    
    map.plot + 
  geom_polygon(data = state_county, aes(x=long, y=lat, group = group), fill = NA, color = "darkblue") + 
    geom_point(aes(x = lon, y = lat, color = accurate), data=plot.data, size = 1.5) +
    scale_color_manual(values=c("#B74611","#77A1D877")) + 
    ggtitle(paste0("randomForest: ntree = ", ntree.x, "  n_model = ", n_model)) + 
    annotate("text")

```


###Neural Network Classification 

Interest in Neural Networks as  a multiple classification machine learning model is growing. The R package `{nnet}` is a popular version of a neural network model based on a [feed-forward multi-layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron).   

In practice, the model required substantial tuning with every paramter adjustemtn. For this case a hidden layer of `size = 12` produced reasonably stable results, though in some cases the `decay` and `rang` variables were tweaked as the number of modeled points in the `train.set` was changed. 

```{r, cache=TRUE}

    coords.y <- coords


    n_model <- 10001

    set.seed(334455)
    data.select <- sample(1:nrow(coords.y), n_model) #nrow(coords.y)*0.5)

    train.set <- coords.y[data.select,]
    
    ## add the classifier variables for the nnet
    train.set$county.class <- class.ind(train.set$county)
    
    test.set <- coords.y[-data.select,]
    
    if (nrow(test.set) > 5000) test.set <- test.set[1:5000,]
    
    decay.x <- 2e-4
    
    model.data.start.time <- proc.time()
        nn.model <- nnet(county.class ~., train.set[,-3], size=12, rang = 0.02, decay = decay.x, maxit = 6000, softmax = TRUE, trace=FALSE)

    nn.model.time <- 1000*(proc.time() - model.data.start.time)[1] %>% as.numeric %>% round(2)
    nn.model.thruput <- (nrow(train.set) / nn.model.time) %>% round(2)
    
    predict.start.time <- proc.time()
    
    predicted.test <- predict(nn.model, test.set[,-3], type='class')

    nn.predict.time <- 1000*(proc.time() - predict.start.time)[1] %>% as.numeric %>% round(2)
    nn.predict.thruput <- (nrow(test.set) / nn.predict.time) %>% round(2)
    

```

The training set is modeled with the following function call. 

```{r eval=FALSE, echo=TRUE}

decay.x <- 2e-4

nn.model <- nnet(county.class ~., train.set[,-3], size = 12, rang = 0.02, decay = decay.x, maxit = 6000, softmax = TRUE, trace=FALSE) 

```

The model converged after about 860 iterations with the above parameters.

Performance was measured in the same way as for the randomForest. Model times were substantially longer than the randomForest. It took `r (nn.model.time/1000.) %>% round(2)` seconds to model `r nrow(train.set)` data points, while prediction of `r nrow(test.set) ` points took `r nn.predict.time` msec.  

```{r}

    county.compare <- cbind("actual" = as.character(test.set$county), "model" = as.character(predicted.test)) %>% as.data.frame()
    county.compare$accurate <- "yes"
    
    ## get rid of factors again
    county.compare$actual <- as.character(county.compare$actual)
    county.compare$model <- as.character(county.compare$model)
    
    county.compare$accurate[(county.compare[,1] != county.compare[,2])] <- "no"
    
    plot.data <- cbind("lat" = test.set$lat, "lon" = test.set$lon, "accurate" = county.compare$accurate) %>% as.data.frame
    
    plot.data$lat <- plot.data$lat %>% as.character %>% as.numeric
    plot.data$lon <- plot.data$lon %>% as.character %>% as.numeric
    
    plot.data$accurate <- as.factor(plot.data$accurate)

```



```{r, results='asis'}
    predict.sum<-table(plot.data$accurate)

    nn.accuracy <- (100*predict.sum[2]/(predict.sum[1]+predict.sum[2])) %>% round(1) %>% as.numeric

    predict.sum <- predict.sum %>% as.data.frame

    colnames(predict.sum) <- c("accurate", "count")

    #print(xtable(predict.sum), type = "html", comment=FALSE, include.rownames=FALSE, html.table.attributes='border="3" align="center" ' )

```

Model accuracy `r nn.accuracy`% is well below our goal of 98%. Note that the model might be improved through more extensive tuning and modeling more data points. However the modeling times were already prohibitively long and model stability with a training set approaching 15,000 data points was problematic, so that effort was abandoned.  
<br>
The accuracy of the modeling results are shown in the map below. 


```{r fig.align='center'}


## use ggmap

    library(ggmap)

    ## get google map (if needed uncomment)
    #map <- get_googlemap(center =  c(lon = -120.31619, lat = 44), zoom = 6, size = c(450, 340), scale = 2, source = "google", maptype="roadmap") #, key = "AIzaSyADdNjbHVwefx-jDyDRPkcSIdcZfznFjc8")
    #map.plot <- ggmap(map)

    # get oregon counties
    counties <- map_data("county")
    state_county <- subset(counties, region == 'oregon')

    nn10001 <- map.plot + 
        geom_polygon(data = state_county, aes(x=long, y=lat, group = group), fill = NA, color = "darkblue") + 
        geom_point(aes(x = lon, y = lat, color = accurate), data=plot.data, size = 1.5) +
        scale_color_manual(values=c("#B74611","#77A1F877")) + 
        ggtitle("nnet model") + 
        annotate("text")
    
    nn10001
        
```

Note that in the case of the `nnet` model, there is, as with other models, substantial error along county boundaries. However, in the case of the `nnet` model, the inaccuracy extends to the county interior in many places, adding yet another reason to conclude the  `nnet` model is less desirable than `randomForest` for this application.   

```{r, eval=FALSE}
    ## compute a comparable randomForest 

    coords.y <- coords

    n_model <- 10001

    set.seed(334455)
    data.select <- sample(1:nrow(coords.y), n_model)

    train.set <- coords.y[data.select,]

    test.set <- coords.y[-data.select,]

    if (nrow(test.set) > 5000) test.set <- test.set[1:5000,]

    set.seed(8675309)
    ntree.x <- 21
    
    start.time <- proc.time()
        rf.model <- randomForest(county ~., train.set, ntree = ntree.x)
    model.time <- (proc.time() - start.time)[1]
    
    start.time <- proc.time()
        predicted.test <- predict(rf.model, test.set)
    predict.time <- (proc.time() - start.time)[1]


    county.compare <- cbind("actual" = as.character(test.set$county), "model" = as.character(predicted.test)) %>% as.data.frame()
    county.compare$accurate <- "yes"
    
    ## get rid of factors again
    county.compare$actual <- as.character(county.compare$actual)
    county.compare$model <- as.character(county.compare$model)
    
    county.compare$accurate[(county.compare[,1] != county.compare[,2])] <- "no"
    
    plot.data <- cbind("lat" = test.set$lat, "lon" = test.set$lon, "accurate" = county.compare$accurate) %>% as.data.frame
    
    plot.data$lat <- plot.data$lat %>% as.character %>% as.numeric
    plot.data$lon <- plot.data$lon %>% as.character %>% as.numeric
    
    plot.data$accurate <- as.factor(plot.data$accurate)


    
predict.sum<-table(plot.data$accurate)

random.Forest.accuracy <- (100*predict.sum[2]/(predict.sum[1]+predict.sum[2])) %>% round(3)


#library(ggmap)
#map = get_googlemap(center =  c(lon = -120.31619, lat = 44), zoom = 6, size = c(450, 340), scale = 2, source = "google", maptype="roadmap") #, key = "AIzaSyADdNjbHVwefx-jDyDRPkcSIdcZfznFjc8")
#map.plot = ggmap(map)

# get oregon counties
#counties <- map_data("county")
#state_county <- subset(counties, region == 'oregon')

rf10001 <- map.plot + 
  geom_polygon(data = state_county, aes(x=long, y=lat, group = group), fill = NA, color = "darkblue") + 
    geom_point(aes(x = lon, y = lat, color = accurate), data=plot.data, size = 0.3) +
    scale_color_manual(values=c("#B74611","#77A1D877")) + 
    ggtitle("randomForest model") + 
    annotate("text")



```
   
  
    
```{r, fig.align='center'}    
    #grid.arrange(nn10001, rf10001, ncol=2)

```


##Summary & Conclusions  

Various reverse-geocoding schemes were explored for both performance and accuracy, including API calls, P-i-P, and classification machine learning models based on both the `randomForest` and `nnet` packages. 

The table summarizes the results. It shows that a `randomForest` model gives accuracy comparable to that of the Google Maps API of nearly 98%, though with a throughput improvement of over 10^4^. 

<br>

```{r, results='asis'}

results.summary <- data_frame("method" = c("API", "P-i-P", "randomForest", "nnet"),
                              "accuracy (%)" = c(api.accuracy, pip.accuracy*100., rf.accuracy, nn.accuracy), 
                              "predict.thruput" = c(1/179 %>% as.numeric %>% round(2), pip.thruput %>% as.numeric, rf.predict.thruput %>% as.numeric, nn.predict.thruput %>% as.numeric),
                              "model.thruput" = c(NA, NA, rf.model.thruput, nn.model.thruput))


results.summary.sorted <- results.summary %>% arrange(desc(predict.thruput))

print(xtable(results.summary.sorted), type = "html", comment=FALSE, 
          include.rownames=FALSE, 
          html.table.attributes='border="3" align="center" ' )

```
<br> 

Modeling throughput times of the `randomForest` are also reasonable (taking several seconds for on the order of 15000 data points on a Intel-based MacBook Air) making it a good choice for the intended application of rapid "on-prem" reverse geocoding.   

While the application of this method has been to counties within State boundaries, it is reasonable this approach can be easily extensible to other reverse geo-coding problems, such as zip codes, congressional districts, and state and national boundaries. This makes the use of a random Forest reverse geocoding approach an attractive options for high performance, high precision reverse geocoding. 









